{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepcs_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G98kYW7RxPP5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfrQVi303Muy"
      },
      "source": [
        "Importing libraries and APIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyfE-Lwe3NDd"
      },
      "source": [
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UylxGZPt3VHc"
      },
      "source": [
        "Unrarring the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFcvSMNM3VbK"
      },
      "source": [
        "!unrar x '/content/drive/MyDrive/use.rawcode.rar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y-pnzJq3fw_"
      },
      "source": [
        "Defining the preprocessing functions.\n",
        "\n",
        "*   *remove_non_ascii*: replaces all non-ASCII characters with an empty string.\n",
        "*   *remove_special*: replaces all special characters in the docstring with an empty string.\n",
        "*   *seperate_strings*: seperates camelCase strings.\n",
        "*   *remove_empty*: removes all empty strings.\n",
        "*   *lowercase*: lowercases all strings in the docstring to avoid case sensitivity.\n",
        "*   *remove_unnecessary*: removes all string values and comments in the code.\n",
        "*   *replace_symbols*: replaces specific programming symbols with their names.\n",
        "*   *trim*: keeps a maximum of 100 code tokens for each code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8na5Dwed3gCe"
      },
      "source": [
        "def remove_non_ascii(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      token_index = row.index(token)\n",
        "      # replacing non-ASCII characters with an empty string.\n",
        "      token = re.sub(r'[^\\x00-\\x7f]', '', token)\n",
        "      data[index][token_index] = token\n",
        "      \n",
        "  return data\n",
        "\n",
        "def remove_special(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      token_index = row.index(token)\n",
        "      # replacing special characters with an empty string.\n",
        "      token = re.sub(r'[^A-Za-z0-9]+', '', token)\n",
        "      data[index][token_index] = token\n",
        "\n",
        "  return data\n",
        "\n",
        "def separate_strings(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      # if the string is in camelCase format.\n",
        "      if re.findall(r'[a-z][^A-Z]*|[A-Z][a-z][^A-Z]*', token):\n",
        "        token_index = row.index(token)\n",
        "        # capitalizing the first letter of the token.\n",
        "        token = token[0].capitalize() + token[1:]\n",
        "        token = re.findall(r'[A-Z][a-z][^A-Z]*|[A-Z]*(?![a-z])|[A-Z][a-z][^A-Z]*', token)\n",
        "        # replacing token with an empty string.\n",
        "        data[index][token_index] = ''\n",
        "        # adding the seperated words to the list preserving their original position.\n",
        "        data[index] = data[index][:token_index] + token + data[index][token_index:]\n",
        "        # updating row.\n",
        "        row = data[index]\n",
        "\n",
        "  return data\n",
        "\n",
        "def remove_empty(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      if not token:  \n",
        "        # removing empty strings from the list.\n",
        "        data[index] = list(filter(None, row))\n",
        "\n",
        "  return data\n",
        "\n",
        "def lowercase(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      token_index = row.index(token)\n",
        "      token = token.lower()\n",
        "      data[index][token_index] = token\n",
        "\n",
        "  return data\n",
        "\n",
        "def remove_unnecessary(data):\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      # if the string contains space, double quotes or is a comment.\n",
        "      if re.findall(r'[ ]', token) or re.findall(r'(\")', token) or re.findall(r'(^//)', token) or re.findall(r'(^/\\*)', token) or re.findall(r'(^/\\*\\*)', token):\n",
        "        token_index = row.index(token)\n",
        "        # replacing token with an empty string.\n",
        "        data[index][token_index] = ''\n",
        "  \n",
        "  return data\n",
        "\n",
        "def replace_symbols(data):\n",
        "  dictionary = {'(': 'openingparenthesis',\n",
        "                ')': 'closingparenthesis',\n",
        "                '[': 'openingbracket', \n",
        "                ']': 'closingbracket',\n",
        "                '{': 'openingbrace', \n",
        "                '}': 'closingbrace',\n",
        "                '+': 'addoperator', \n",
        "                '-': 'subtractoperator',\n",
        "                '*': 'multiplyoperator', \n",
        "                '/': 'divideoperator',\n",
        "                '^': 'poweroperator', \n",
        "                '%': 'modulooperator',\n",
        "                '=': 'assignoperator', \n",
        "                '==': 'equaloperator',\n",
        "                '!=': 'notequaloperator', \n",
        "                '>': 'greateroperator',\n",
        "                '<': 'lessoperator', \n",
        "                '>=': 'greaterequaloperator',\n",
        "                '<=': 'lessequaloperator', \n",
        "                '++': 'incrementoperator',\n",
        "                '--': 'decrementoperator', \n",
        "                '!': 'notoperator',\n",
        "                '@': 'atsign',\n",
        "                ';': 'semicolon'}\n",
        "\n",
        "  for index, row in data.iteritems():\n",
        "    for token in row:\n",
        "      # if the string contains one or more of the following symbols.\n",
        "      if re.findall(r'^[()[\\]{}<>+\\-*/^%=!@;]', token):\n",
        "        token_index = row.index(token)\n",
        "        # replacing token with the name of the symbol contained.\n",
        "        for symbol, name in dictionary.items():\n",
        "          if token == symbol:\n",
        "            data[index][token_index] = name\n",
        "        \n",
        "  return data\n",
        "\n",
        "def trim(data):\n",
        "  for index, row in data.iteritems():\n",
        "    if len(row) > 100:\n",
        "      data[index] = row[:100]\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mJNWUgA3tLs"
      },
      "source": [
        "Applying preprocressing to the code tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DSESsM2W3suu"
      },
      "source": [
        "for deepcs_tokens in pd.read_csv('/content/use.rawcode.txt', sep='\\n', encoding='latin', header=None, chunksize=1000000):\n",
        "  deepcs_tokens = deepcs_tokens.squeeze().str.split()\n",
        "\n",
        "  deepcs_tokens = remove_non_ascii(deepcs_tokens)\n",
        "  deepcs_tokens = separate_strings(deepcs_tokens)\n",
        "  deepcs_tokens = remove_unnecessary(deepcs_tokens)\n",
        "  deepcs_tokens = replace_symbols(deepcs_tokens)\n",
        "  deepcs_tokens = remove_special(deepcs_tokens)\n",
        "  deepcs_tokens = remove_empty(deepcs_tokens)\n",
        "  deepcs_tokens = trim(deepcs_tokens)\n",
        "  deepcs_tokens = lowercase(deepcs_tokens)\n",
        "\n",
        "  deepcs_tokens.to_csv('/content/drive/MyDrive/deepcs_tokens.csv', mode='a', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}